{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-05T13:19:35.797954Z","iopub.execute_input":"2021-12-05T13:19:35.798466Z","iopub.status.idle":"2021-12-05T13:19:35.841405Z","shell.execute_reply.started":"2021-12-05T13:19:35.798366Z","shell.execute_reply":"2021-12-05T13:19:35.840728Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\nfrom tensorflow.keras.models import Sequential\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport os\nimport cv2\nfrom keras.preprocessing.image import img_to_array\n\n# x is noisy data and y is clean data\nSIZE = 2048\n\nfrom tqdm import tqdm\nfolder = '../input/bad-img'\nfiles=os.listdir(folder)\nprint(files)\nsortedfiles=sorted(files)\nprint(sortedfiles)\nnoisy_data=[]\nfor filename in sortedfiles:\n    img = cv2.imread(os.path.join(folder, filename), cv2.IMREAD_COLOR)\n    img=cv2.resize(img,(SIZE, SIZE))\n    noisy_data.append(img_to_array(img))\n\nfolder1 = '../input/good-img'\nfiles1=os.listdir(folder1)\nprint(files1)\nsortedfiles1=sorted(files1)\nprint(sortedfiles1)\nclean_data=[]\nfor filename in sortedfiles1:\n    img = cv2.imread(os.path.join(folder1, filename), cv2.IMREAD_COLOR)\n    img=cv2.resize(img,(SIZE, SIZE))\n    clean_data.append(img_to_array(img))\n\nnoisy_train = np.reshape(noisy_data, (len(noisy_data), SIZE, SIZE, 3))\nnoisy_train = noisy_train.astype('float32') / 255.\n\nclean_train = np.reshape(clean_data, (len(clean_data), SIZE, SIZE, 3))\nclean_train = clean_train.astype('float32') / 255.\n\n\n#Displaying images with noise\nplt.figure(figsize=(10, 2))\nfor i in range(1,4):\n    ax = plt.subplot(1, 4, i)\n    plt.imshow(cv2.cvtColor(noisy_train[i].reshape(SIZE, SIZE,3), cv2.COLOR_BGR2RGB))\nplt.show()\n\n#Displaying clean images\nplt.figure(figsize=(10, 2))\nfor i in range(1,4):\n    ax = plt.subplot(1, 4, i)\n    plt.imshow(cv2.cvtColor(clean_train[i].reshape(SIZE, SIZE,3), cv2.COLOR_BGR2RGB))\nplt.show()\n\n\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(SIZE, SIZE, 3)))\nmodel.add(MaxPooling2D((2, 2), padding='same'))\nmodel.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\nmodel.add(MaxPooling2D((2, 2), padding='same'))\nmodel.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\n \n\nmodel.add(MaxPooling2D((2, 2), padding='same'))\n     \nmodel.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(8, (3, 3), activation='relu', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(3, (3, 3), activation='relu', padding='same'))\n\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n\nmodel.summary()\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(noisy_train, clean_train, \n                                                    test_size = 0.05, random_state = 0)\n\n\nmodel.fit(x_train, y_train, epochs=60, batch_size=1, shuffle=True, verbose =1,\n          validation_split = 0.3)\n\n\nprint(\"Test_Accuracy: {:.2f}%\".format(model.evaluate(np.array(x_test), np.array(y_test))[1]*100))\n\n\n#model.save('denoising_autoencoder.model')\n\nno_noise_img = model.predict(x_test)\n\n#Displaying images with noise\nplt.figure(figsize=(10, 2))\nfor i in range(1,2):\n    ax = plt.subplot(1, 4, i)\n    img0=cv2.cvtColor(x_test[i-1].reshape(SIZE, SIZE,3), cv2.COLOR_BGR2RGB)\n    #plt.imsave('./noised_image.jpg', img0)\n    plt.imshow(cv2.cvtColor(x_test[i-1].reshape(SIZE, SIZE,3), cv2.COLOR_BGR2RGB))\nplt.show()\n\n#Displaying clean images\nplt.figure(figsize=(10, 2))\nfor i in range(1,2):\n    ax = plt.subplot(1, 4, i)\n    img1=cv2.cvtColor(no_noise_img[i-1].reshape(SIZE, SIZE,3), cv2.COLOR_BGR2RGB)\n    plt.imsave('./denoised_image.jpg', img1)\n    #plt.imshow(cv2.cvtColor(no_noise_img[i-1].reshape(SIZE, SIZE,3), cv2.COLOR_BGR2RGB))\n    plt.imshow(cv2.cvtColor(no_noise_img[i-1].reshape(SIZE, SIZE,3), cv2.COLOR_BGR2RGB))\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2021-12-05T13:19:45.332490Z","iopub.execute_input":"2021-12-05T13:19:45.333038Z","iopub.status.idle":"2021-12-05T13:22:34.842816Z","shell.execute_reply.started":"2021-12-05T13:19:45.332994Z","shell.execute_reply":"2021-12-05T13:22:34.842098Z"},"trusted":true},"execution_count":2,"outputs":[]}]}